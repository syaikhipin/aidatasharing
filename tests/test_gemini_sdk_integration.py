#!/usr/bin/env python3
"""
AI Share Platform - Gemini Integration Test with MindsDB SDK

This test script validates the complete Gemini integration using MindsDB SDK
for data chat functionality.
"""

import os
import sys
import json
import time
import logging
from datetime import datetime
from typing import Dict, Any, List
import pandas as pd

# Add the backend path to sys.path
backend_path = os.path.join(os.path.dirname(__file__), '..', 'backend')
sys.path.insert(0, backend_path)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class GeminiSDKIntegrationTest:
    """Test class for Gemini SDK integration."""
    
    def __init__(self):
        self.test_results = {
            "total_tests": 0,
            "passed": 0,
            "failed": 0,
            "errors": [],
            "test_details": []
        }
        self.mindsdb_service = None
        
    def setup(self):
        """Setup test environment."""
        try:
            logger.info("ğŸ”§ Setting up test environment...")
            
            # Import and configure settings
            from app.core.config import settings
            
            # Check required environment variables
            required_vars = {
                'GOOGLE_API_KEY': settings.GOOGLE_API_KEY,
                'MINDSDB_URL': settings.MINDSDB_URL
            }
            
            for var_name, var_value in required_vars.items():
                if not var_value:
                    raise Exception(f"Required environment variable {var_name} is not set")
                logger.info(f"âœ… {var_name}: {'*' * (len(str(var_value)) - 10) + str(var_value)[-10:] if var_name == 'GOOGLE_API_KEY' else var_value}")
            
            # Initialize MindsDB service
            from app.services.mindsdb import MindsDBService
            self.mindsdb_service = MindsDBService()
            
            logger.info("âœ… Test environment setup complete")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Setup failed: {e}")
            return False
    
    def run_test(self, test_name: str, test_func) -> bool:
        """Run a single test and track results."""
        self.test_results["total_tests"] += 1
        
        try:
            logger.info(f"ğŸ§ª Running test: {test_name}")
            start_time = time.time()
            
            result = test_func()
            
            end_time = time.time()
            duration = end_time - start_time
            
            if result:
                self.test_results["passed"] += 1
                logger.info(f"âœ… {test_name} - PASSED ({duration:.2f}s)")
                self.test_results["test_details"].append({
                    "name": test_name,
                    "status": "PASSED",
                    "duration": duration,
                    "timestamp": datetime.now().isoformat()
                })
                return True
            else:
                self.test_results["failed"] += 1
                logger.error(f"âŒ {test_name} - FAILED ({duration:.2f}s)")
                self.test_results["test_details"].append({
                    "name": test_name,
                    "status": "FAILED",
                    "duration": duration,
                    "timestamp": datetime.now().isoformat()
                })
                return False
                
        except Exception as e:
            self.test_results["failed"] += 1
            error_msg = f"{test_name}: {str(e)}"
            self.test_results["errors"].append(error_msg)
            logger.error(f"âŒ {test_name} - ERROR: {e}")
            self.test_results["test_details"].append({
                "name": test_name,
                "status": "ERROR",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
            return False
    
    def test_mindsdb_connection(self) -> bool:
        """Test MindsDB SDK connection."""
        try:
            health = self.mindsdb_service.health_check()
            
            if health.get("status") == "error":
                logger.warning("MindsDB not available, but this is acceptable (will use fallback)")
                return True
            
            logger.info("ğŸ§  MindsDB connection successful")
            logger.info(f"  Connection status: {health.get('connection')}")
            logger.info(f"  Engine status: {health.get('engine_status', 'unknown')}")
            
            return True
            
        except Exception as e:
            logger.error(f"MindsDB connection test failed: {e}")
            return False
    
    def test_gemini_engine_creation(self) -> bool:
        """Test Gemini engine creation via SDK."""
        try:
            result = self.mindsdb_service.create_gemini_engine()
            
            if result.get("status") in ["created", "exists"]:
                logger.info(f"ğŸ”§ Gemini engine: {result.get('message')}")
                return True
            else:
                logger.error(f"Engine creation failed: {result}")
                return False
                
        except Exception as e:
            logger.error(f"Gemini engine creation failed: {e}")
            return False
    
    def test_chat_model_creation(self) -> bool:
        """Test chat model creation."""
        try:
            result = self.mindsdb_service.create_gemini_model(
                model_name="test_chat_model",
                model_type="chat",
                column_name="question"  # Use correct parameter name
            )
            
            if result.get("status") in ["created", "exists"]:
                logger.info(f"ğŸ¤– Chat model: {result.get('message')}")
                return True
            else:
                logger.error(f"Chat model creation failed: {result}")
                return False
                
        except Exception as e:
            logger.error(f"Chat model creation failed: {e}")
            return False
    
    def test_basic_ai_chat(self) -> bool:
        """Test basic AI chat functionality."""
        try:
            test_message = "Hello! Can you tell me what 2+2 equals?"
            response = self.mindsdb_service.ai_chat(test_message)
            
            if response.get("answer"):
                logger.info(f"ğŸ’¬ AI Chat successful")
                logger.info(f"  Question: {test_message}")
                logger.info(f"  Answer: {response.get('answer')[:100]}...")
                logger.info(f"  Model: {response.get('model')}")
                logger.info(f"  Source: {response.get('source')}")
                return True
            else:
                logger.error(f"AI chat failed: No answer received")
                return False
                
        except Exception as e:
            logger.error(f"AI chat test failed: {e}")
            return False
    
    def test_dataset_model_creation(self) -> bool:
        """Test dataset-specific model creation."""
        try:
            test_dataset_id = 999
            test_dataset_name = "test_sales_data"
            
            result = self.mindsdb_service.create_dataset_ml_model(
                dataset_id=test_dataset_id,
                dataset_name=test_dataset_name,
                dataset_type="CSV"
            )
            
            if result.get("success"):
                logger.info(f"ğŸ“Š Dataset model created: {result.get('message')}")
                logger.info(f"  Model name: {result.get('chat_model')}")
                logger.info(f"  Engine: {result.get('engine')}")
                return True
            else:
                logger.error(f"Dataset model creation failed: {result.get('error')}")
                return False
                
        except Exception as e:
            logger.error(f"Dataset model creation failed: {e}")
            return False
    
    def test_dataset_chat(self) -> bool:
        """Test dataset-specific chat functionality."""
        try:
            test_dataset_id = 999
            test_message = "What insights can you provide about this sales dataset?"
            
            response = self.mindsdb_service.chat_with_dataset(
                dataset_id=test_dataset_id,
                message=test_message
            )
            
            if response.get("answer"):
                logger.info(f"ğŸ“Š Dataset chat successful")
                logger.info(f"  Dataset ID: {test_dataset_id}")
                logger.info(f"  Question: {test_message}")
                logger.info(f"  Answer: {response.get('answer')[:150]}...")
                logger.info(f"  Model: {response.get('model', 'unknown')}")
                logger.info(f"  Source: {response.get('source', 'unknown')}")
                
                # Check if it's using dataset-specific model or fallback
                if response.get("source") == "mindsdb_dataset_model":
                    logger.info("  âœ… Using dataset-specific model")
                else:
                    logger.info("  âš ï¸ Using fallback model (acceptable)")
                
                return True
            else:
                logger.error(f"Dataset chat failed: No answer received")
                return False
                
        except Exception as e:
            logger.error(f"Dataset chat test failed: {e}")
            return False
    
    def test_gemini_integration_initialization(self) -> bool:
        """Test complete Gemini integration initialization."""
        try:
            result = self.mindsdb_service.initialize_gemini_integration()
            
            if result.get("overall_status") == "success":
                logger.info("ğŸš€ Gemini integration initialization successful")
                
                components = result.get("components", {})
                for component, details in components.items():
                    status = details.get("status")
                    if status == "success":
                        logger.info(f"  âœ… {component}: OK")
                    else:
                        logger.warning(f"  âš ï¸ {component}: {details.get('error', 'Unknown error')}")
                
                config = result.get("configuration", {})
                logger.info(f"  Engine: {config.get('engine_name')}")
                logger.info(f"  API Key: {'âœ… Configured' if config.get('api_key_configured') else 'âŒ Missing'}")
                logger.info(f"  Connection: {config.get('connection_status')}")
                
                return True
            else:
                logger.error(f"Integration initialization failed: {result.get('error')}")
                return False
                
        except Exception as e:
            logger.error(f"Integration initialization test failed: {e}")
            return False
    
    def test_model_listing(self) -> bool:
        """Test model listing functionality."""
        try:
            result = self.mindsdb_service.list_models()
            
            if result.get("error"):
                logger.warning(f"Model listing had issues: {result.get('error')}")
                # This might be acceptable if MindsDB is not fully available
                return True
            
            models = result.get("data", [])
            count = result.get("count", 0)
            
            logger.info(f"ğŸ“‹ Models listed successfully: {count} models found")
            
            if models:
                for model in models[:3]:  # Show first 3 models
                    logger.info(f"  ğŸ“ {model.get('name')} - Status: {model.get('status', 'unknown')}")
            
            return True
            
        except Exception as e:
            logger.error(f"Model listing test failed: {e}")
            return False
    
    def test_error_handling(self) -> bool:
        """Test error handling and fallback mechanisms."""
        try:
            # Test with invalid input
            response = self.mindsdb_service.ai_chat("")
            
            if response.get("answer") or response.get("error"):
                logger.info("ğŸ›¡ï¸ Error handling working correctly")
                return True
            else:
                logger.error("Error handling test failed")
                return False
                
        except Exception as e:
            # Exception is expected for some error cases
            logger.info(f"ğŸ›¡ï¸ Error handling working (caught exception: {type(e).__name__})")
            return True
    
    def create_sample_data(self) -> bool:
        """Create sample data for testing."""
        try:
            # Create a simple CSV file for testing
            sample_data = {
                'product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones'],
                'price': [999.99, 29.99, 79.99, 299.99, 149.99],
                'quantity': [10, 50, 25, 15, 30],
                'category': ['Electronics', 'Accessories', 'Accessories', 'Electronics', 'Accessories']
            }
            
            df = pd.DataFrame(sample_data)
            sample_file = os.path.join(os.path.dirname(__file__), 'test_sample_data.csv')
            df.to_csv(sample_file, index=False)
            
            logger.info(f"ğŸ“„ Sample data created: {sample_file}")
            return True
            
        except Exception as e:
            logger.error(f"Sample data creation failed: {e}")
            return False
    
    def cleanup(self):
        """Cleanup test resources."""
        try:
            logger.info("ğŸ§¹ Cleaning up test resources...")
            
            # Clean up test dataset models
            try:
                self.mindsdb_service.delete_dataset_models(999)
                logger.info("âœ… Test dataset models cleaned up")
            except Exception as e:
                logger.warning(f"Dataset model cleanup warning: {e}")
            
            # Remove sample data file
            try:
                sample_file = os.path.join(os.path.dirname(__file__), 'test_sample_data.csv')
                if os.path.exists(sample_file):
                    os.remove(sample_file)
                    logger.info("âœ… Sample data file removed")
            except Exception as e:
                logger.warning(f"Sample file cleanup warning: {e}")
            
            logger.info("âœ… Cleanup completed")
            
        except Exception as e:
            logger.error(f"âŒ Cleanup failed: {e}")
    
    def print_summary(self):
        """Print test summary."""
        results = self.test_results
        
        print("\n" + "=" * 80)
        print("ğŸ§ª GEMINI SDK INTEGRATION TEST SUMMARY")
        print("=" * 80)
        print(f"ğŸ“Š Total Tests: {results['total_tests']}")
        print(f"âœ… Passed: {results['passed']}")
        print(f"âŒ Failed: {results['failed']}")
        print(f"ğŸ“ˆ Success Rate: {(results['passed'] / results['total_tests'] * 100):.1f}%")
        
        if results['errors']:
            print(f"\nâŒ ERRORS:")
            for error in results['errors']:
                print(f"  â€¢ {error}")
        
        print(f"\nğŸ“‹ DETAILED RESULTS:")
        for test in results['test_details']:
            status_emoji = "âœ…" if test['status'] == "PASSED" else "âŒ"
            duration = test.get('duration', 0)
            print(f"  {status_emoji} {test['name']} ({duration:.2f}s)")
            if test.get('error'):
                print(f"      Error: {test['error']}")
        
        print("=" * 80)
        
        # Save results to file
        try:
            results_file = os.path.join(os.path.dirname(__file__), 'test_results', 'gemini_sdk_test_results.json')
            os.makedirs(os.path.dirname(results_file), exist_ok=True)
            
            with open(results_file, 'w') as f:
                json.dump(results, f, indent=2)
            
            print(f"ğŸ“„ Test results saved to: {results_file}")
        except Exception as e:
            print(f"âš ï¸ Failed to save results: {e}")
        
        print("=" * 80)
    
    def run_all_tests(self):
        """Run all tests in sequence."""
        logger.info("ğŸš€ Starting Gemini SDK Integration Tests...")
        print("=" * 80)
        print("ğŸ§ª AI SHARE PLATFORM - GEMINI SDK INTEGRATION TEST")
        print("=" * 80)
        
        # Setup
        if not self.setup():
            logger.error("âŒ Setup failed, aborting tests")
            return False
        
        # Create sample data
        self.run_test("Sample Data Creation", self.create_sample_data)
        
        # Core connectivity tests
        self.run_test("MindsDB Connection", self.test_mindsdb_connection)
        self.run_test("Gemini Engine Creation", self.test_gemini_engine_creation)
        self.run_test("Chat Model Creation", self.test_chat_model_creation)
        
        # Functionality tests
        self.run_test("Basic AI Chat", self.test_basic_ai_chat)
        self.run_test("Dataset Model Creation", self.test_dataset_model_creation)
        self.run_test("Dataset Chat", self.test_dataset_chat)
        
        # Integration tests
        self.run_test("Gemini Integration Init", self.test_gemini_integration_initialization)
        self.run_test("Model Listing", self.test_model_listing)
        self.run_test("Error Handling", self.test_error_handling)
        
        # Cleanup
        self.cleanup()
        
        # Print summary
        self.print_summary()
        
        return self.test_results['failed'] == 0


def main():
    """Main test function."""
    test_runner = GeminiSDKIntegrationTest()
    
    try:
        success = test_runner.run_all_tests()
        
        if success:
            logger.info("ğŸ‰ All tests passed!")
            sys.exit(0)
        else:
            logger.error("âŒ Some tests failed!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Tests interrupted by user")
        test_runner.cleanup()
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ Test runner failed: {e}")
        test_runner.cleanup()
        sys.exit(1)


if __name__ == "__main__":
    main() 